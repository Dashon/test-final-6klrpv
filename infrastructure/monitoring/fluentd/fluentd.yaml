# Production-grade Fluentd deployment manifest for centralized logging
# Version: v1.16-debian-elasticsearch7-1
apiVersion: v1
kind: List
items:
# 1. ServiceAccount with restricted permissions
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: fluentd
    namespace: monitoring
    annotations:
      security.policy/restricted: "true"
    labels:
      app: fluentd
      component: logging

# 2. ClusterRole with minimal required permissions
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: fluentd
    labels:
      app: fluentd
      component: logging
  rules:
  - apiGroups: [""]
    resources: ["pods", "namespaces"]
    verbs: ["get", "list", "watch"]

# 3. ClusterRoleBinding to associate ServiceAccount with ClusterRole
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: fluentd
    labels:
      app: fluentd
      component: logging
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: fluentd
  subjects:
  - kind: ServiceAccount
    name: fluentd
    namespace: monitoring

# 4. ConfigMap with optimized Fluentd configuration
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: fluentd-config
    namespace: monitoring
    labels:
      app: fluentd
      component: logging
  data:
    fluent.conf: |
      # Input configurations
      <source>
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/fluentd-containers.log.pos
        tag kubernetes.*
        read_from_head true
        <parse>
          @type json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      # Kubernetes metadata enrichment
      <filter kubernetes.**>
        @type kubernetes_metadata
        @id filter_kube_metadata
        kubernetes_url "#{ENV['KUBERNETES_URL']}"
        cache_size 10000
        watch true
        verify_ssl true
      </filter>

      # Record transformation and enrichment
      <filter kubernetes.**>
        @type record_transformer
        enable_ruby true
        auto_typecast true
        <record>
          environment "#{ENV['ENVIRONMENT']}"
          cluster_name "#{ENV['CLUSTER_NAME']}"
          log_timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%N%:z')}
        </record>
      </filter>

      # Output configuration for Elasticsearch
      <match kubernetes.**>
        @type elasticsearch
        @id elasticsearch
        host "#{ENV['ELASTICSEARCH_HOST']}"
        port "#{ENV['ELASTICSEARCH_PORT']}"
        logstash_format true
        logstash_prefix logstash
        include_timestamp true
        
        # Buffer configuration
        <buffer>
          @type file
          path /var/log/fluentd-buffers/kubernetes.system.buffer
          flush_mode interval
          retry_type exponential_backoff
          flush_interval 5s
          retry_forever false
          retry_max_interval 30
          chunk_limit_size 256m
          queue_limit_length 8
          overflow_action block
        </buffer>

        # Connection configuration
        reconnect_on_error true
        reload_on_failure true
        reload_connections false
        request_timeout 30s
        
        # Compression
        compression_level 6
        compression gzip
      </match>

# 5. DaemonSet for deploying Fluentd on all nodes
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: fluentd
    namespace: monitoring
    labels:
      app: fluentd
      component: logging
  spec:
    selector:
      matchLabels:
        app: fluentd
    updateStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 30%
    template:
      metadata:
        labels:
          app: fluentd
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "24231"
      spec:
        serviceAccountName: fluentd
        priorityClassName: system-node-critical
        terminationGracePeriodSeconds: 30
        # Node tolerations for master nodes
        tolerations:
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
        containers:
        - name: fluentd
          image: fluent/fluentd-kubernetes-daemonset:v1.16-debian-elasticsearch7-1
          imagePullPolicy: IfNotPresent
          env:
          - name: FLUENT_ELASTICSEARCH_HOST
            value: elasticsearch.monitoring.svc.cluster.local
          - name: FLUENT_ELASTICSEARCH_PORT
            value: "9200"
          - name: KUBERNETES_URL
            value: "https://kubernetes.default.svc"
          - name: ENVIRONMENT
            valueFrom:
              configMapKeyRef:
                name: monitoring-config
                key: environment
          - name: CLUSTER_NAME
            valueFrom:
              configMapKeyRef:
                name: monitoring-config
                key: cluster_name
          resources:
            limits:
              memory: 500Mi
              cpu: 500m
            requests:
              memory: 200Mi
              cpu: 100m
          volumeMounts:
          - name: varlog
            mountPath: /var/log
          - name: varlibdockercontainers
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: fluentd-config
            mountPath: /fluentd/etc
          - name: buffer-volume
            mountPath: /var/log/fluentd-buffers
          securityContext:
            runAsNonRoot: true
            runAsUser: 2000
            readOnlyRootFilesystem: true
          livenessProbe:
            httpGet:
              path: /metrics
              port: 24231
            initialDelaySeconds: 30
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /metrics
              port: 24231
            initialDelaySeconds: 5
            periodSeconds: 10
        volumes:
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: fluentd-config
          configMap:
            name: fluentd-config
        - name: buffer-volume
          emptyDir: {}